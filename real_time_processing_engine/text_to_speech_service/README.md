# Text-to-Speech (TTS) Service

## Purpose

The Text-to-Speech (TTS) Service is a component of the RevoVoiceAI Real-Time Processing Engine. Its core responsibility is to convert textual input into synthesized speech audio. This service is crucial for generating voice responses in a conversational AI system. Currently, it acts as a placeholder, acknowledging text receipt rather than generating actual audio.

## Components

*   `service.py`: Contains the gRPC `TextToSpeechServicer` which implements the placeholder TTS logic.
*   `tts_service_pb2.py`: Generated Protobuf Python code for TTS message structures.
*   `tts_service_pb2_grpc.py`: Generated Protobuf Python code for TTS gRPC client and server stubs.
*   `requirements.txt`: Python package dependencies (`grpcio`, `grpcio-tools`, `protobuf`).
*   `config.py`: (Placeholder) For service-specific configurations (e.g., voice models).
*   `voices/`: (Placeholder directory) For voice model files.
*   `__init__.py`: Makes the directory a Python package.

## gRPC Service: TextToSpeechService

The TTS Service exposes its functionality via a gRPC interface.

*   **Service Name:** `TextToSpeechService` (defined in `real_time_processing_engine/protos/tts_service.proto`)
*   **Port:** The gRPC server listens on `0.0.0.0:50055`.
*   **RPC Method:** `SynthesizeText(TTSRequest) returns (TTSResponse)`
    *   **`TTSRequest`**: Contains the `text_to_synthesize`, `session_id`, and an optional `voice_config_id`.
    *   **`TTSResponse`**: Returns the `session_id`, a `status_message`, and now includes `audio_data` (containing dummy/simulated PCM audio) and `audio_format` (e.g., PCMU) as per the updated proto definition.

## Current Status & Logic

The current implementation of the `TextToSpeechServicer` in `service.py` is a **placeholder**.
*   It logs the `text_to_synthesize`, `session_id`, and `voice_config_id` it receives.
*   It returns a `TTSResponse` with a `status_message` confirming that the text has been received and that dummy audio is being returned (e.g., "Simulated TTS for session '[session_id]': Returning dummy PCMU audio.").
*   **Simulated audio data is generated.** It returns a `TTSResponse` with a `status_message` and a small, fixed snippet of dummy PCM audio data (e.g., PCMU format) in the `audio_data` field, with `audio_format` set accordingly. The main purpose is to test the pipeline's ability to handle audio in responses. Future development will integrate a real TTS engine.

## Interaction in the System

1.  **Input**: Receives a `TTSRequest` from the `DialogueManagementService`. The `text_to_synthesize` field contains the system's response generated by the DM.
2.  **Processing**: The `TextToSpeechServicer.SynthesizeText()` method logs the request and prepares a status message.
3.  **Output**: Returns a `TTSResponse` (containing the status message) to the `DialogueManagementService`.
4.  **Next Step (Conceptual for real audio)**: In a fully implemented system, the TTS service would generate audio data. This audio would then be streamed or sent to the Voice Gateway Layer for playback to the user. Currently, the `DialogueManagementService` only logs the status message from this placeholder TTS service.

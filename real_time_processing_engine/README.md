# RevoVoiceAI - Real-Time Processing Engine

This directory contains the services that form the core of the Real-Time Processing Engine for RevoVoiceAI. These services are responsible for handling live audio input and output, performing initial processing, and orchestrating interactions with the AI/ML layer.

## Services

Currently, the following services are outlined:

*   **`streaming_data_manager`**: Manages incoming data streams (e.g., audio from calls) and routes them to appropriate processing services.
*   **`speech_to_text_service`**: Responsible for transcribing audio streams into text.
*   **`text_to_speech_service`**: Converts textual responses into audible speech.
*   **`vad_service` (Voice Activity Detection Service)**: Detects speech and silence segments in an audio stream, aiding in efficient processing.
*   **`audio_processing_pipeline_service` (Audio Processing Pipeline Service)**: Applies various audio processing operations (e.g., noise reduction, echo cancellation, format conversion) to enhance audio quality.
*   *(Other services might be added here later)*

## Conceptual Full Voice Interaction Flow

A typical flow for a complete voice interaction:

1.  **Call Initiation / Voice Input**:
    *   An external component (like a Voice Gateway) signals the start of a new audio stream (e.g., an incoming call).
    *   The `StreamingDataManager` registers this new audio stream.
2.  **Voice Activity Detection (VAD) & Audio Pre-processing**:
    *   The `StreamingDataManager` routes the incoming audio stream/chunks.
    *   Optionally, the `AudioProcessingPipelineService` can apply initial clean-up (e.g., noise reduction, echo cancellation if sensor-level).
    *   The `VADService` processes audio chunks to identify segments containing speech.
    *   Further audio processing via `AudioProcessingPipelineService` can be applied to VAD output segments (e.g., more targeted noise reduction on speech).
3.  **Speech-to-Text (STT) Processing**:
    *   The `SpeechToTextService` transcribes the cleaned and (potentially VAD-filtered) audio from the previous step into plain text.
4.  **AI/ML Processing (External to this Engine)**:
    *   The transcribed text is passed to the AI/ML Services Layer.
    *   **Natural Language Understanding (NLU)** service processes the text to identify intents and entities.
    *   **Dialogue Management (DM)** service takes the NLU output, manages conversation state, and decides on the next action or response text.
5.  **Text-to-Speech (TTS) Processing**:
    *   The response text generated by the Dialogue Management service (from the AI/ML layer) is sent to the `TextToSpeechService` within this engine.
    *   The `TextToSpeechService` converts this text into an audio stream (e.g., WAV data).
6.  **Audio Post-processing & Output**:
    *   The synthesized audio stream from the TTS service can be further processed by the `AudioProcessingPipelineService` (e.g., for format conversion to meet telephony requirements, final gain adjustment, or applying specific audio effects).
    *   The final audio is then passed to the Voice Gateway Layer (not implemented here) to be played back to the user.

This engine provides the crucial components for bidirectional voice communication, bridging the gap between raw audio and the intelligent processing layers, and ensuring audio quality throughout the interaction.
